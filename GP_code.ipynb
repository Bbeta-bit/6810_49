{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7511f85-c364-42dc-acf4-4fc432d35b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import numpy as np\n",
    "import scipy \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pygam\n",
    "import sklearn\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(f'Package versions: \\n')\n",
    "print(f'numpy {np.__version__}')\n",
    "print(f'scipy {scipy.__version__}')\n",
    "print(f'pandas {pd.__version__}')\n",
    "print(f'seaborn {sns.__version__}')\n",
    "print(f'pygam {pygam.__version__}')\n",
    "print(f'scikit-learn {sklearn.__version__}')\n",
    "print(f'optuna {optuna.__version__}')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfb75c-c75a-49eb-a472-d7ed2aac9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olist_customers_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_customers_dataset.csv')\n",
    "df_olist_geolocation_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_geolocation_dataset.csv')\n",
    "df_olist_order_items_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_order_items_dataset.csv')\n",
    "df_olist_order_payments_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_order_payments_dataset.csv')\n",
    "df_olist_order_reviews_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_order_reviews_dataset.csv')\n",
    "df_olist_orders_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_orders_dataset.csv')\n",
    "df_olist_products_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_products_dataset.csv')\n",
    "df_olist_sellers_dataset = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/olist_sellers_dataset.csv')\n",
    "df_product_category_name_translation = pd.read_csv('/Users/guojingwei/Documents/USYD/6810/group assignment/Olist Dataset/product_category_name_translation.csv')\n",
    "\n",
    "df_olist_order_reviews_dataset = df_olist_order_reviews_dataset.rename(columns={'review_id': 'customer_id'})\n",
    "\n",
    "df_temp = pd.merge(df_olist_order_items_dataset, df_olist_order_payments_dataset, on='order_id')\n",
    "df_order_based = pd.merge(df_temp, df_olist_orders_dataset, on='order_id')\n",
    "\n",
    "df_order_medium = pd.merge(df_order_based, df_olist_products_dataset, on='product_id')\n",
    "df_order_final = pd.merge(df_order_medium, df_olist_sellers_dataset, on='seller_id')\n",
    "df_customer = pd.merge(df_olist_customers_dataset, df_olist_orders_dataset, on='customer_id')\n",
    "df_merged = pd.merge(df_order_final, df_customer, on='order_id')\n",
    "\n",
    "df_merged.info()\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c9f76-e9c4-4722-bf8c-8d2c36a91ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AOV = df_merged.groupby('customer_unique_id').agg(\n",
    "    total_order_amount=('price', 'sum'),\n",
    "    order_count=('order_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "df_AOV['AOV'] = df_AOV['total_order_amount'] / df_AOV['order_count']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_merged_with_AOV = pd.merge(df_merged, df_AOV, on='customer_unique_id')\n",
    "print(df_merged_with_AOV)\n",
    "\n",
    "response = ['AOV']\n",
    "continuous = [\n",
    "    'price', 'freight_value', 'payment_value',\n",
    "    'product_name_lenght', 'product_description_lenght',\n",
    "    'product_photos_qty', 'product_weight_g',\n",
    "    'product_length_cm', 'product_height_cm', 'product_width_cm'\n",
    "]\n",
    "\n",
    "discrete = [\n",
    "    'payment_installments', 'payment_sequential'\n",
    "]\n",
    "\n",
    "binary = [\n",
    "    'payment_type', 'product_category_name', 'seller_state', 'customer_state'\n",
    "]\n",
    "\n",
    "predictors = continuous + discrete + binary\n",
    "    \n",
    "df_merged_with_AOV = df_merged_with_AOV[response + predictors]\n",
    "\n",
    "\n",
    "X = df_merged_with_AOV[predictors]\n",
    "y = df_merged_with_AOV['AOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea06268-73d2-43f8-aaef-1c31b4bd938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[predictors].info())\n",
    "print(train[predictors].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d9c2a-1e94-4dcd-bbec-53403edd47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train[predictors]))\n",
    "print(len(y_train))\n",
    "print(pd.Series(y_train).isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58661730-1ceb-4e8b-bd94-72396d0e6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[predictors].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeee4c9-d8ea-45e2-9044-0b0007bdf35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split indexes\n",
    "index_train, index_valid  = train_test_split(np.array(df_merged_with_AOV.index), train_size=0.7, random_state=1)\n",
    "\n",
    "# Write training and validation sets \n",
    "train = df_merged_with_AOV.loc[index_train,:].copy()\n",
    "valid =  df_merged_with_AOV.loc[index_valid,:].copy()\n",
    "\n",
    "y_train= train['AOV'].to_numpy()\n",
    "y_valid = valid['AOV'].to_numpy()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train.loc[:, continuous + discrete] = scaler.fit_transform(train.loc[:, continuous + discrete])\n",
    "valid.loc[:, continuous + discrete] = scaler.transform(valid.loc[:, continuous + discrete])\n",
    "\n",
    "X_train = train[predictors]\n",
    "X_valid = valid[predictors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33379165-0b52-496b-9a3c-676d4801848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relationships(X, y, lowess=False):\n",
    "    \"\"\"Plot the relationship between each predictor and the target variable.\"\"\"\n",
    "    # Feature names and setup\n",
    "    features = X.columns\n",
    "    num_features = len(features)\n",
    "    rows = (num_features + 2) // 3  # Calculate rows needed (3 plots per row)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, rows * 4))\n",
    "    axes = axes.flatten()  # Flatten to easily iterate\n",
    "    \n",
    "    # Plot each feature\n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            # Scatter with smoothed line\n",
    "            sns.regplot(x=X[feature], y=y, lowess=lowess, \n",
    "                       scatter_kws={'alpha': 0.5}, ax=axes[i])\n",
    "            axes[i].set_title(f'{feature} vs AOV')\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel('AOV')\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for i in range(num_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "fig = plot_relationships(train[predictors], y_train, lowess=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a26806-3dc6-482d-bd9f-47d10de5592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_plot_spline(feature, n_knots, degree, y_train, train_data):\n",
    "    \"\"\"Fit a spline with specified parameters and plot the results.\"\"\"\n",
    "    # Create the spline transformer\n",
    "    spline = SplineTransformer(n_knots=n_knots, degree=degree, knots='uniform', include_bias=False)\n",
    "    X_spline = spline.fit_transform(train_data[[feature]].values)\n",
    "    \n",
    "    # Fit linear regression on spline features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_spline, y_train)\n",
    "    \n",
    "    # Create grid for visualization\n",
    "    x_min = train_data[feature].min()\n",
    "    x_max = train_data[feature].max()\n",
    "    x_grid = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    X_grid = spline.transform(x_grid)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_grid)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(train_data[feature], y_train, alpha=0.4, label='Data')\n",
    "    plt.plot(x_grid, y_pred, linewidth=2, \n",
    "             label=f'degree {degree} spline with {n_knots} knots')\n",
    "    plt.xlabel(f'{feature} (standardized)')\n",
    "    plt.ylabel('Customer Lifetime Value')\n",
    "    plt.title(f'Regression Spline: Degree {degree} with {n_knots} knots')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "# Linear spline with 4 knots\n",
    "fit_and_plot_spline('total_order_amount', n_knots=4, degree=1, y_train=y_train, train_data=train)\n",
    "\n",
    "# Cubic spline with 5 knots\n",
    "fit_and_plot_spline('total_order_amount', n_knots=5, degree=3, y_train=y_train, train_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05643387-433f-49b6-b67d-f50478dabf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_plot_spline(feature, n_knots, degree, y_train, train_data):\n",
    "    \"\"\"Fit a spline with specified parameters and plot the results.\"\"\"\n",
    "    # Create the spline transformer\n",
    "    spline = SplineTransformer(n_knots=n_knots, degree=degree, knots='uniform', include_bias=False)\n",
    "    X_spline = spline.fit_transform(train_data[[feature]].values)\n",
    "    \n",
    "    # Fit linear regression on spline features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_spline, y_train)\n",
    "    \n",
    "    # Create grid for visualization\n",
    "    x_min = train_data[feature].min()\n",
    "    x_max = train_data[feature].max()\n",
    "    x_grid = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "    X_grid = spline.transform(x_grid)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_grid)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(train_data[feature], y_train, alpha=0.4, label='Data')\n",
    "    plt.plot(x_grid, y_pred, linewidth=2, \n",
    "             label=f'degree {degree} spline with {n_knots} knots')\n",
    "    plt.xlabel(f'{feature} (standardized)')\n",
    "    plt.ylabel('Customer Lifetime Value')\n",
    "    plt.title(f'Regression Spline: Degree {degree} with {n_knots} knots')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "from pygam import LinearGAM, s, l\n",
    "\n",
    "# Define the model: s() for smooth terms, l() for linear terms\n",
    "gam = LinearGAM(\n",
    "    s(0) +  # Acq_Expense: smooth term\n",
    "    s(1) +  # Ret_Expense: smooth term \n",
    "    l(2) +  # First_Purchase: linear term\n",
    "    l(3) +  # Revenue: linear term\n",
    "    l(4) +  # Employees: linear term\n",
    "    l(5) +  # Frequency: linear term\n",
    "    l(6) +  # Crossbuy: linear term\n",
    "    l(7)    # Industry: linear term\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "gam.fit(X_train, y_train)\n",
    "\n",
    "# Display model summary\n",
    "print(gam.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b20178-e556-4c7c-a5a0-4b7cb6085a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the partial dependence for each feature\n",
    "plt.figure(figsize=(16, 20))\n",
    "\n",
    "# Track the plot position\n",
    "plot_idx = 1\n",
    "\n",
    "for i, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "        \n",
    "    # Create subplot (2 plots per row)\n",
    "    plt.subplot(4, 2, plot_idx)\n",
    "    plot_idx += 1\n",
    "    \n",
    "    # Generate points for plotting\n",
    "    X_grid = gam.generate_X_grid(term=i)\n",
    "    \n",
    "    # Get the partial dependence and confidence intervals\n",
    "    pdep, confi = gam.partial_dependence(term=i, X= X_grid, width=0.95)\n",
    "    \n",
    "    # Plot the function\n",
    "    plt.plot(X_grid[:, term.feature], pdep)\n",
    "    plt.plot( X_grid[:, term.feature], confi, c='grey', ls='--', alpha=0.5)\n",
    "    \n",
    "    # Label the plot\n",
    "    plt.title(predictors[i])\n",
    "    plt.grid(True, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5446c-dd5d-4c57-abe1-02524f727ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # Swithing off ouput, you want to remove this line to see more details\n",
    "\n",
    "# Define a simple objective function to minimize\n",
    "def objective(trial):\n",
    "    # Parameter to optimize\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    \n",
    "    # The function to minimize: (x-2)²\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "# Create a study object and optimize\n",
    "sampler = optuna.samplers.TPESampler(seed=42)  # For reproducibility\n",
    "study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print results\n",
    "print(f\"Best value: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf254f-292a-4400-a2f8-aec557cfbf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gam_objective(trial):\n",
    "    # Separate lambda parameters for different term types\n",
    "    lambda_spline_acq = trial.suggest_float('lambda_spline_acq', 1e-4, 1e4, log=True)\n",
    "    lambda_spline_ret = trial.suggest_float('lambda_spline_ret', 1e-4, 1e4, log=True)\n",
    "    lambda_linear = trial.suggest_float('lambda_linear', 1e-4, 1e4, log=True)\n",
    "    \n",
    "    # Create lambda list with appropriate values for each term\n",
    "    lambdas = [\n",
    "        lambda_spline_acq,  # Acq_Expense (spline)\n",
    "        lambda_spline_ret,  # Ret_Expense (spline)\n",
    "        lambda_linear,   # First_Purchase (linear)\n",
    "        lambda_linear,   # Revenue (linear)\n",
    "        lambda_linear,   # Employees (linear)\n",
    "        lambda_linear,   # Frequency (linear)\n",
    "        lambda_linear,   # Crossbuy (linear)\n",
    "        lambda_linear    # Industry (linear)\n",
    "    ]\n",
    "    \n",
    "    # Create and fit the GAM with these lambda values\n",
    "    model = LinearGAM(s(0) + s(1) + l(2) + l(3) + l(4) + l(5) + l(6) + l(7), \n",
    "                      lam=lambdas)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Return the GCV score\n",
    "    return model.statistics_['GCV']\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)  # makes the sampler behave in a deterministic way\n",
    "\n",
    "study = optuna.create_study(direction='minimize', sampler=sampler) # TPE is a method for Bayesian optimisation\n",
    "study.optimize(gam_objective, n_trials=10000, timeout=120) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24a572-33a6-4342-ad09-b2600ada9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambdas = list(study.best_params.values())\n",
    "\n",
    "lambda_spline_acq = best_lambdas[0]\n",
    "lambda_spline_ret = best_lambdas[1]\n",
    "lambda_linear = best_lambdas[2]\n",
    "    \n",
    "# Create lambda list with appropriate values for each term\n",
    "lambdas = [\n",
    "    lambda_spline_acq,  # Acq_Expense (spline)\n",
    "    lambda_spline_ret,  # Ret_Expense (spline)\n",
    "    lambda_linear,   # First_Purchase (linear)\n",
    "    lambda_linear,   # Revenue (linear)\n",
    "    lambda_linear,   # Employees (linear)\n",
    "    lambda_linear,   # Frequency (linear)\n",
    "    lambda_linear,   # Crossbuy (linear)\n",
    "    lambda_linear    # Industry (linear)\n",
    "]\n",
    "\n",
    "\n",
    "optimized_gam = LinearGAM(s(0) + s(1) + l(2) + l(3) + l(4) + l(5) + l(6) + l(7), lam = lambdas)\n",
    "optimized_gam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3cd13-3dad-466c-b78b-4d2bfef4c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gam.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d49e2-07e9-4553-8063-112d3605b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "plot_idx = 1\n",
    "\n",
    "for i, term in enumerate(optimized_gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "        \n",
    "    plt.subplot(4, 2, plot_idx)\n",
    "    plot_idx += 1\n",
    "    \n",
    "    X_grid = optimized_gam.generate_X_grid(term=i)\n",
    "    pdep, confi = optimized_gam.partial_dependence(term=i, X=X_grid, width=0.95)\n",
    "    \n",
    "    plt.plot(X_grid[:, term.feature], pdep)\n",
    "    plt.plot(X_grid[:, term.feature], confi, c='grey', ls='--', alpha=0.5)\n",
    "    \n",
    "    plt.title(f\"{predictors[i]}\")\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.ylim(-1.5, 1.5) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
